{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. tl;dr\n",
    "\n",
    "Complete the functions\n",
    "* `construct_laplacian` (4pt)\n",
    "* `spectral_embedding` (2pt)\n",
    "* `compute_ratio_cut`(2pt)\n",
    "* `compute_normalized_cut` (2pt)\n",
    "\n",
    "in `clustering.py`, then push the file to the remote Artemis respository.\n",
    "\n",
    "For `spectral_embedding`, please use the provided function `deterministic_eigsh` and not `scipy.sparse.linalg.eigsh`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Task 4: Spectral clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this task is to find groups of users with similar preferences using **Spectral clustering**. \n",
    "You are given a fragment of the Yelp social network, represented by an undirected weighted graph.\n",
    "Nodes in the graph represent users.\n",
    "If two users are connected by an edge of weight $w$, it means that they have both left positive reviews to the same $w$ restaurants.\n",
    "\n",
    "Additionally, you are given a matrix `F` that encodes user preferences to different categories of restaurants. If `F[i, c] = 1`, then user `i` likes restaurants in category `c`.\n",
    "\n",
    "## General remarks\n",
    "Where possible, please use sparse matrix operations (see [Scipy Sparse](https://docs.scipy.org/doc/scipy/reference/sparse.html)). Otherwise, we cannot guarantee that your code will run on the test machines.\n",
    "\n",
    "Do not add or modify any code outside of the following comment blocks, or where otherwise explicitly stated.\n",
    "\n",
    "``` python\n",
    "##########################################################\n",
    "# YOUR CODE HERE\n",
    "...\n",
    "##########################################################\n",
    "```\n",
    "\n",
    "The following things are **NOT** allowed:\n",
    "- Using additional `import` statements **and submodules of `sp` are not allowed such as `sp.csgraph.laplacian`**\n",
    "- Copying / reusing code from other sources (e.g. code by other students)\n",
    "- Posting your code in public threads on Piazza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "* `N` = number of users (nodes in the graph)\n",
    "* `C` = number of categories\n",
    "* The graph is stored as a _sparse adjacency matrix_ `A` (shape `[N, N]`).\n",
    "* User preferences are stored in a _feature matrix_ `F` (shape `[N, C]`). They will only be used for the final part of the assignment (Part 3)\n",
    "* Name of each category is provided in the list `categories` (length `[C]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = sp.load_npz('A.npz')\n",
    "F = np.load('F.npy')\n",
    "categories = np.load('categories.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert A.shape[0] == F.shape[0]\n",
    "assert F.shape[1] == len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The adjacency matrix is symmetric\n"
     ]
    }
   ],
   "source": [
    "print(f'The adjacency matrix is {\"symmetric\" if (A != A.T).sum() == 0 else \"asymmetric\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Spectral clustering (6pt)\n",
    "## 1.1. Constructing the graph Laplacian (4pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need functionality to construct the Laplacian for the given graph.\n",
    "\n",
    "Given the **adjacency matrix** $A \\in \\mathbb{R}^{N \\times N},$ we define the **degree matrix** $D \\in \\mathbb{R}^{N \\times N}$ of an undirected graph as\n",
    "$$D_{ij} =  \\begin{cases}\\sum_{k=1}^N A_{ik} & if \\;\\; i = j\\\\ 0 & if \\;\\; i \\ne j\\end{cases}$$\n",
    "\n",
    "If our goal is to minimize the **ratio cut**, we use the **unnormalized Laplacian**, defined as\n",
    "$$L_{unnorm} = D - A.$$\n",
    "\n",
    "If our goal is to minimze the **normalized cut**, we use the **normalized Laplacian** (a.k.a. symmetrized Laplacian), defined as\n",
    "$$L_{sym} = I - D^{-1/2}AD^{-1/2}$$\n",
    "\n",
    "**Before proceeding, implement the following function** from ``clustering.py``:\n",
    "* `construct_laplacian` (4pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering import construct_laplacian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Spectral embedding (2 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to use the implemented functionality to compute spectral embeddings.\n",
    "\n",
    "This spectral embedding is given by the $k$ smallest eigenvalues of:\n",
    "* the unnormalized Laplacian, if we want to minimize the ratio cut,\n",
    "* the normalized Laplacian, if we want to minimize the normalized cut.\n",
    "\n",
    "Since the Laplacian matrix is sparse and symmetric, we can use the function `eigsh` from the `scipy.sparse.linalg` package in order to find eigendecomposition of $L$ (`eig` - eigendecomposition, `s` - sparse, `h`- Hermitian).\n",
    "The function `eigsh` directly allows you to find the smallest / largest eigenvalues by specifying the `k` and `which` parameters. \n",
    "\n",
    "Keep in mind that the Laplacian matrix is always positive semi-definite when picking the appropriate value for the `which` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function eigsh in module scipy.sparse.linalg.eigen.arpack.arpack:\n",
      "\n",
      "eigsh(A, k=6, M=None, sigma=None, which='LM', v0=None, ncv=None, maxiter=None, tol=0, return_eigenvectors=True, Minv=None, OPinv=None, mode='normal')\n",
      "    Find k eigenvalues and eigenvectors of the real symmetric square matrix\n",
      "    or complex hermitian matrix A.\n",
      "    \n",
      "    Solves ``A * x[i] = w[i] * x[i]``, the standard eigenvalue problem for\n",
      "    w[i] eigenvalues with corresponding eigenvectors x[i].\n",
      "    \n",
      "    If M is specified, solves ``A * x[i] = w[i] * M * x[i]``, the\n",
      "    generalized eigenvalue problem for w[i] eigenvalues\n",
      "    with corresponding eigenvectors x[i].\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    A : ndarray, sparse matrix or LinearOperator\n",
      "        A square operator representing the operation ``A * x``, where ``A`` is\n",
      "        real symmetric or complex hermitian. For buckling mode (see below)\n",
      "        ``A`` must additionally be positive-definite.\n",
      "    k : int, optional\n",
      "        The number of eigenvalues and eigenvectors desired.\n",
      "        `k` must be smaller than N. It is not possible to compute all\n",
      "        eigenvectors of a matrix.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    w : array\n",
      "        Array of k eigenvalues.\n",
      "    v : array\n",
      "        An array representing the `k` eigenvectors.  The column ``v[:, i]`` is\n",
      "        the eigenvector corresponding to the eigenvalue ``w[i]``.\n",
      "    \n",
      "    Other Parameters\n",
      "    ----------------\n",
      "    M : An N x N matrix, array, sparse matrix, or linear operator representing\n",
      "        the operation ``M @ x`` for the generalized eigenvalue problem\n",
      "    \n",
      "            A @ x = w * M @ x.\n",
      "    \n",
      "        M must represent a real, symmetric matrix if A is real, and must\n",
      "        represent a complex, hermitian matrix if A is complex. For best\n",
      "        results, the data type of M should be the same as that of A.\n",
      "        Additionally:\n",
      "    \n",
      "            If sigma is None, M is symmetric positive definite.\n",
      "    \n",
      "            If sigma is specified, M is symmetric positive semi-definite.\n",
      "    \n",
      "            In buckling mode, M is symmetric indefinite.\n",
      "    \n",
      "        If sigma is None, eigsh requires an operator to compute the solution\n",
      "        of the linear equation ``M @ x = b``. This is done internally via a\n",
      "        (sparse) LU decomposition for an explicit matrix M, or via an\n",
      "        iterative solver for a general linear operator.  Alternatively,\n",
      "        the user can supply the matrix or operator Minv, which gives\n",
      "        ``x = Minv @ b = M^-1 @ b``.\n",
      "    sigma : real\n",
      "        Find eigenvalues near sigma using shift-invert mode.  This requires\n",
      "        an operator to compute the solution of the linear system\n",
      "        ``[A - sigma * M] x = b``, where M is the identity matrix if\n",
      "        unspecified.  This is computed internally via a (sparse) LU\n",
      "        decomposition for explicit matrices A & M, or via an iterative\n",
      "        solver if either A or M is a general linear operator.\n",
      "        Alternatively, the user can supply the matrix or operator OPinv,\n",
      "        which gives ``x = OPinv @ b = [A - sigma * M]^-1 @ b``.\n",
      "        Note that when sigma is specified, the keyword 'which' refers to\n",
      "        the shifted eigenvalues ``w'[i]`` where:\n",
      "    \n",
      "            if mode == 'normal', ``w'[i] = 1 / (w[i] - sigma)``.\n",
      "    \n",
      "            if mode == 'cayley', ``w'[i] = (w[i] + sigma) / (w[i] - sigma)``.\n",
      "    \n",
      "            if mode == 'buckling', ``w'[i] = w[i] / (w[i] - sigma)``.\n",
      "    \n",
      "        (see further discussion in 'mode' below)\n",
      "    v0 : ndarray, optional\n",
      "        Starting vector for iteration.\n",
      "        Default: random\n",
      "    ncv : int, optional\n",
      "        The number of Lanczos vectors generated ncv must be greater than k and\n",
      "        smaller than n; it is recommended that ``ncv > 2*k``.\n",
      "        Default: ``min(n, max(2*k + 1, 20))``\n",
      "    which : str ['LM' | 'SM' | 'LA' | 'SA' | 'BE']\n",
      "        If A is a complex hermitian matrix, 'BE' is invalid.\n",
      "        Which `k` eigenvectors and eigenvalues to find:\n",
      "    \n",
      "            'LM' : Largest (in magnitude) eigenvalues.\n",
      "    \n",
      "            'SM' : Smallest (in magnitude) eigenvalues.\n",
      "    \n",
      "            'LA' : Largest (algebraic) eigenvalues.\n",
      "    \n",
      "            'SA' : Smallest (algebraic) eigenvalues.\n",
      "    \n",
      "            'BE' : Half (k/2) from each end of the spectrum.\n",
      "    \n",
      "        When k is odd, return one more (k/2+1) from the high end.\n",
      "        When sigma != None, 'which' refers to the shifted eigenvalues ``w'[i]``\n",
      "        (see discussion in 'sigma', above).  ARPACK is generally better\n",
      "        at finding large values than small values.  If small eigenvalues are\n",
      "        desired, consider using shift-invert mode for better performance.\n",
      "    maxiter : int, optional\n",
      "        Maximum number of Arnoldi update iterations allowed.\n",
      "        Default: ``n*10``\n",
      "    tol : float\n",
      "        Relative accuracy for eigenvalues (stopping criterion).\n",
      "        The default value of 0 implies machine precision.\n",
      "    Minv : N x N matrix, array, sparse matrix, or LinearOperator\n",
      "        See notes in M, above.\n",
      "    OPinv : N x N matrix, array, sparse matrix, or LinearOperator\n",
      "        See notes in sigma, above.\n",
      "    return_eigenvectors : bool\n",
      "        Return eigenvectors (True) in addition to eigenvalues.\n",
      "        This value determines the order in which eigenvalues are sorted.\n",
      "        The sort order is also dependent on the `which` variable.\n",
      "    \n",
      "            For which = 'LM' or 'SA':\n",
      "                If `return_eigenvectors` is True, eigenvalues are sorted by\n",
      "                algebraic value.\n",
      "    \n",
      "                If `return_eigenvectors` is False, eigenvalues are sorted by\n",
      "                absolute value.\n",
      "    \n",
      "            For which = 'BE' or 'LA':\n",
      "                eigenvalues are always sorted by algebraic value.\n",
      "    \n",
      "            For which = 'SM':\n",
      "                If `return_eigenvectors` is True, eigenvalues are sorted by\n",
      "                algebraic value.\n",
      "    \n",
      "                If `return_eigenvectors` is False, eigenvalues are sorted by\n",
      "                decreasing absolute value.\n",
      "    \n",
      "    mode : string ['normal' | 'buckling' | 'cayley']\n",
      "        Specify strategy to use for shift-invert mode.  This argument applies\n",
      "        only for real-valued A and sigma != None.  For shift-invert mode,\n",
      "        ARPACK internally solves the eigenvalue problem\n",
      "        ``OP * x'[i] = w'[i] * B * x'[i]``\n",
      "        and transforms the resulting Ritz vectors x'[i] and Ritz values w'[i]\n",
      "        into the desired eigenvectors and eigenvalues of the problem\n",
      "        ``A * x[i] = w[i] * M * x[i]``.\n",
      "        The modes are as follows:\n",
      "    \n",
      "            'normal' :\n",
      "                OP = [A - sigma * M]^-1 @ M,\n",
      "                B = M,\n",
      "                w'[i] = 1 / (w[i] - sigma)\n",
      "    \n",
      "            'buckling' :\n",
      "                OP = [A - sigma * M]^-1 @ A,\n",
      "                B = A,\n",
      "                w'[i] = w[i] / (w[i] - sigma)\n",
      "    \n",
      "            'cayley' :\n",
      "                OP = [A - sigma * M]^-1 @ [A + sigma * M],\n",
      "                B = M,\n",
      "                w'[i] = (w[i] + sigma) / (w[i] - sigma)\n",
      "    \n",
      "        The choice of mode will affect which eigenvalues are selected by\n",
      "        the keyword 'which', and can also impact the stability of\n",
      "        convergence (see [2] for a discussion).\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    ArpackNoConvergence\n",
      "        When the requested convergence is not obtained.\n",
      "    \n",
      "        The currently converged eigenvalues and eigenvectors can be found\n",
      "        as ``eigenvalues`` and ``eigenvectors`` attributes of the exception\n",
      "        object.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    eigs : eigenvalues and eigenvectors for a general (nonsymmetric) matrix A\n",
      "    svds : singular value decomposition for a matrix A\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This function is a wrapper to the ARPACK [1]_ SSEUPD and DSEUPD\n",
      "    functions which use the Implicitly Restarted Lanczos Method to\n",
      "    find the eigenvalues and eigenvectors [2]_.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] ARPACK Software, http://www.caam.rice.edu/software/ARPACK/\n",
      "    .. [2] R. B. Lehoucq, D. C. Sorensen, and C. Yang,  ARPACK USERS GUIDE:\n",
      "       Solution of Large Scale Eigenvalue Problems by Implicitly Restarted\n",
      "       Arnoldi Methods. SIAM, Philadelphia, PA, 1998.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from scipy.sparse.linalg import eigsh\n",
      "    >>> identity = np.eye(13)\n",
      "    >>> eigenvalues, eigenvectors = eigsh(identity, k=6)\n",
      "    >>> eigenvalues\n",
      "    array([1., 1., 1., 1., 1., 1.])\n",
      "    >>> eigenvectors.shape\n",
      "    (13, 6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(eigsh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before proceeding, implement the following function** from ``clustering.py``:\n",
    "* `construct_laplacian` (2pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering import spectral_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Determining the clusters based on the spectral embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the spectral embeddings, we can use k-means clustering to assign nodes to clusters.\n",
    "\n",
    "Note that when using the **normalized Laplacian**, the rows of the embedding matrix **have to** be normalized to have unit $L_2$ norm. The justification of this approach is not trivial. If you are interested, the paper \"A tutorial on spectral clustering\" by Ulrike von Luxburg. Section 7 covers a justification involving Perturbation Theory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "import scipy.sparse as sp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_clustering(A: sp.csr_matrix, num_clusters: int, norm_laplacian: bool, seed: int = 42) -> np.array:\n",
    "    \"\"\"Perform spectral clustering on the given graph.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : scipy.sparse.csr_matrix, shape [N, N]\n",
    "        Adjacency matrix of the graph.\n",
    "    num_clusters : int\n",
    "        Number of clusters to detect in the data.\n",
    "    norm_laplacian : bool, default False\n",
    "        Whether to use the normalized graph Laplacian or not.\n",
    "    seed : int, default 42\n",
    "        Random seed to use for the `KMeans` clustering.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    z_pred : np.array, shape [N]\n",
    "        Predicted cluster indicators for each node.\n",
    "        \n",
    "    \"\"\"\n",
    "    model = KMeans(num_clusters, random_state=seed)\n",
    "\n",
    "    embedding = spectral_embedding(A, num_clusters, norm_laplacian)\n",
    "    if norm_laplacian == True:\n",
    "        embedding = normalize(embedding, norm='l2', axis=1)\n",
    "    z_pred = model.fit_predict(embedding)\n",
    "\n",
    "    return z_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Quantitative evaluation (4 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your next task is to implement functions for computing the **ratio cut** and **normalized cut** for a given partition.\n",
    "\n",
    "Ratio cut and normalized cut are defined on page 14 of the lecture slides.  \n",
    "The expression $vol(C_i)$ refers to the number of edges incident to nodes from cluster $C_i$.\n",
    "\n",
    "The function `labels_to_list_of_clusters` in `clustering.py` can be helpful here.\n",
    "\n",
    "**Before proceeding, implement the following function** from ``clustering.py``:\n",
    "* `compute_ratio_cut` (2pt)\n",
    "* `compute_normalized_cut` (2pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering import compute_ratio_cut, compute_normalized_cut, labels_to_list_of_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, how using the unnormalized Laplacian leads to a much better ratio cut, while the normalized Laplacian leads to better normalized cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-8fea3a91db03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12903\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnorm_laplacian\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mz_unnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspectral_clustering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_laplacian\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'When using L_unnorm:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' ratio cut = {:.3f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompute_ratio_cut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_unnorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-c93e216a57d4>\u001b[0m in \u001b[0;36mspectral_clustering\u001b[1;34m(A, num_clusters, norm_laplacian, seed)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnorm_laplacian\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mz_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mz_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36mfit_predict\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1031\u001b[0m             \u001b[0mIndex\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m \u001b[0mbelongs\u001b[0m \u001b[0mto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \"\"\"\n\u001b[1;32m-> 1033\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1467\u001b[0m             \u001b[1;31m# run a k-means once\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1468\u001b[1;33m             labels, inertia, centers, n_iter_ = kmeans_single(\n\u001b[0m\u001b[0;32m   1469\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1470\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36m_kmeans_single_lloyd\u001b[1;34m(X, sample_weight, centers_init, max_iter, verbose, tol, n_threads)\u001b[0m\n\u001b[0;32m    677\u001b[0m     \u001b[1;31m# Threadpoolctl context to limit the number of threads in second level of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[1;31m# nested parallelism (i.e. BLAS) to avoid oversubscription.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 679\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mthreadpool_limits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"blas\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    680\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m             lloyd_iter(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36mthreadpool_limits\u001b[1;34m(limits, user_api)\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcontroller\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muser_api\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mthreadpoolctl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreadpool_limits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muser_api\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, limits, user_api)\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_threadpool_limits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m_set_threadpool_limits\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         modules = _ThreadpoolInfo(prefixes=self._prefixes,\n\u001b[0m\u001b[0;32m    269\u001b[0m                                   user_api=self._user_api)\n\u001b[0;32m    270\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, user_api, prefixes, modules)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_modules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_if_incompatible_openmp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m_load_modules\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_modules_with_dyld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"win32\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_modules_with_enum_process_module_ex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_modules_with_dl_iterate_phdr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m_find_modules_with_enum_process_module_ex\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m                 \u001b[1;31m# Store the module if it is supported and selected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_module_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    486\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mkernel_32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCloseHandle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_process\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m_make_module_from_path\u001b[1;34m(self, filepath)\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefixes\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0muser_api\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m                 \u001b[0mmodule_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule_class\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m                 \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minternal_api\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath, prefix, user_api, internal_api)\u001b[0m\n\u001b[0;32m    604\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal_api\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minternal_api\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dynlib\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_RTLD_NOLOAD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_threads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_num_threads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_extra_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36mget_version\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    644\u001b[0m                              lambda: None)\n\u001b[0;32m    645\u001b[0m         \u001b[0mget_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"OpenBLAS\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "np.random.seed(12903)\n",
    "norm_laplacian = False\n",
    "z_unnorm = spectral_clustering(A, num_clusters, norm_laplacian)\n",
    "print('When using L_unnorm:')\n",
    "print(' ratio cut = {:.3f}'.format(compute_ratio_cut(A, z_unnorm)))\n",
    "print(' normalized cut = {:.3f}'.format(compute_normalized_cut(A, z_unnorm)))\n",
    "print(' sizes of partitions are: {}'.format([len(clust) for clust in labels_to_list_of_clusters(z_unnorm)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When using L_norm:\n",
      " ratio cut = 5942.851\n",
      " normalized cut = 4.343\n",
      " sizes of partitions are: [742, 577, 754, 572, 350, 389]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12323)\n",
    "norm_laplacian = True\n",
    "z_norm = spectral_clustering(A, num_clusters, norm_laplacian)\n",
    "print('When using L_norm:')\n",
    "print(' ratio cut = {:.3f}'.format(compute_ratio_cut(A, z_norm)))\n",
    "print(' normalized cut = {:.3f}'.format(compute_normalized_cut(A, z_norm)))\n",
    "print(' sizes of partitions are: {}'.format([len(clust) for clust in labels_to_list_of_clusters(z_norm)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Visualizing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use our clustering methods to determine the most popular restaurant categories in each cluster and how many positive ratings were given by users of that cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_categories_for_each_cluster(top_k: int, z: np.array, F: sp.csr_matrix, categories: List[str]):\n",
    "    \"\"\"Print the top-K categories among users in each cluster.\n",
    "    For each cluster, the function prints names of the top-K categories,\n",
    "    and number of users that like the respective category (separated by a comma).\n",
    "    The function doesn't return anything, just prints the output.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    top_k : int\n",
    "        Number of most popular categories to print for each cluster.\n",
    "    z : np.array, shape [N]\n",
    "        Cluster labels.\n",
    "    F : sp.csr_matrix, shape [N, C]\n",
    "        Matrix that tells preferences of each user to each category.\n",
    "        F[i, c] = 1 if user i gave at least one positive review to at least one restaurant in category c.\n",
    "    categories : list, shape [C]\n",
    "        Names of the categories.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    list_of_clusters = labels_to_list_of_clusters(z)\n",
    "    \n",
    "    for ix, clust in enumerate(list_of_clusters):\n",
    "        cat_ratings = sum(F[i] for i in clust)\n",
    "        top_cats = np.argsort(-cat_ratings)[:top_k]\n",
    "        print('Most popular categories in cluster {}'.format(ix))\n",
    "        for t in top_cats:\n",
    "            print(f' - {categories[t]}, {int(cat_ratings[t])}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular categories in cluster 0\n",
      " - Breakfast & Brunch, 636\n",
      " - Sandwiches, 528\n",
      " - Italian, 514\n",
      " - Pizza, 482\n",
      " - Coffee & Tea, 473\n",
      "\n",
      "Most popular categories in cluster 1\n",
      " - Japanese, 529\n",
      " - Chinese, 441\n",
      " - Asian Fusion, 414\n",
      " - Sushi Bars, 408\n",
      " - Korean, 406\n",
      "\n",
      "Most popular categories in cluster 2\n",
      " - Breakfast & Brunch, 664\n",
      " - Italian, 626\n",
      " - American (Traditional), 518\n",
      " - Sandwiches, 518\n",
      " - Pizza, 485\n",
      "\n",
      "Most popular categories in cluster 3\n",
      " - Japanese, 507\n",
      " - Breakfast & Brunch, 462\n",
      " - Sandwiches, 435\n",
      " - Italian, 417\n",
      " - Asian Fusion, 414\n",
      "\n",
      "Most popular categories in cluster 4\n",
      " - Seafood, 315\n",
      " - Mexican, 314\n",
      " - Sandwiches, 294\n",
      " - Japanese, 291\n",
      " - Breakfast & Brunch, 286\n",
      "\n",
      "Most popular categories in cluster 5\n",
      " - Specialty Food, 356\n",
      " - Thai, 355\n",
      " - Breakfast & Brunch, 348\n",
      " - Japanese, 333\n",
      " - Ethnic Food, 330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(23142)\n",
    "z_norm = spectral_clustering(A, num_clusters, True)\n",
    "r = print_top_categories_for_each_cluster(5, z_norm, F, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
